{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import timeit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "from plotly import graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, Audio, display_html, clear_output\n",
    "sr = 16000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We are testing the model on 10% of the train data. For this purpose we can load all the data to RAM. Later we will train a model on the full data where we will have to handle data loading inside the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"D:\\\\Projects\\\\silero-audio-classification\"\n",
    "PERCENT = 10 # take PERCENT% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_val(ROOT_DIR):\n",
    "    train, val = train_test_split(pd.read_csv(\"train.csv\"))\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             wav_path   label  target\n",
      "180003      180003  train/9/53d07af.wav   noise       2\n",
      "142078      142078  train/e/150099e.wav  speech       0\n",
      "217976      217976  train/a/6ef577b.wav   music       1\n",
      "78879        78879  train/3/a28c181.wav   music       1\n",
      "252235      252235  train/e/10ba136.wav  speech       0\n",
      "--------------------------------------------------\n",
      "3 target classes found:\n",
      "{2: 'noise', 0: 'speech', 1: 'music'}\n"
     ]
    }
   ],
   "source": [
    "train, val = load_train_val(ROOT_DIR)\n",
    "\n",
    "train = train[:len(train)*PERCENT//100]\n",
    "val = val[:len(val)*PERCENT//100]\n",
    "print(train.head(), end=\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "target_to_text = {elem: name for name, elem in zip(train[\"label\"].unique(), train[\"target\"].unique())}\n",
    "N = len(target_to_text)\n",
    "print(f\"{N} target classes found:\")\n",
    "print(target_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wav(ROOT_DIR, filepath):\n",
    "    path = ROOT_DIR + '\\\\' + filepath\n",
    "    wav, _ = librosa.load(path, sr=sr)\n",
    "    melspec = librosa.feature.melspectrogram(wav, sr=sr)\n",
    "    freq = melspec.sum(axis=1)\n",
    "    freqdb = torch.from_numpy(librosa.power_to_db(freq)).to(device)\n",
    "    mean = freqdb.mean()\n",
    "    std = freqdb.std()\n",
    "    eps = 1e-6\n",
    "    freq_norm = (freqdb - mean) / (std + eps)\n",
    "    freq_min, freq_max = freq_norm.min(), freq_norm.max()\n",
    "    freq_scaled = 255 * (freq_norm - freq_min) / (freq_max - freq_min)\n",
    "    freq = freq_scaled.float().cpu()\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAJOCAYAAAC3EA1tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZAt51nn+d+TeZba7ipL8pXkFcuA2Y3YaSCwadxAYzczgAlgTA/Rno6moRlgegzRMzAxzQTdM0EM7R5Me8DI07gxHlYHuy2GZmtsy8YYy7It2bK160q6W61nyXzmjzq36rylu+jeOnkyz5PfT0TGrScrq8771Jvn1HPzPPWmubsAAADaIKt7AAAAAPNC4QMAAFqDwgcAALQGhQ8AAGgNCh8AANAaFD4AAKA1GlX4mNmGmb247nHUycyeP/k55HWP5Xq0YQ7bkOPVcJ7GZmZ3mtm/rnscVVqUHDlXL+9657BTxWCul7uv1T2Gurn7g5IW9ufQhjlsQ45Xw3kKzAfn6uw16ooPAABAlSopfMzsU2b2Y2b2ITM7b2a/ZmZLk8/9EzO738zOmNk7zeyWqa9zM3vJ5ONvMrOPmNm6mT1iZj82ddy3mNkHzeycmf2VmX1+FXlcIbf/YZLbppn9kpndbGZ/MBnru83shJl9nZk9fImvfeXk4y81s7vN7IKZPWFmPzvZ/8LJz6EziU+a2S+b2aNmdtbMfnuOeYacwzbkyHm6mHNoZv/jZAzrZvYxM3uFmf2Umf36JLd1M/uAmX3B1NfcYma/YWZPmtkDZvZDU5/LzOwNZvYJM3vazN5hZienPv/Vk7zOmdlDZvZ9U8M5YWa/N3nM95jZZ5DjofIOc64u/By6+8w3SZ+S9F5Jt0g6KeleSf9U0tdLekrSyyX1Jb1R0p9NfZ1Lesnk48ck/b3JxyckvXzy8cslnZb0ZZJySa+bPF6/ilwuk9tfS7pZ0q2TsXxA0hdNcvoTST8p6eskPXyJr33l5OP/Iul7Jx+vSfryyccvnPwcOpP49yT92uRn0JX0tXPMM+QctiFHztPFm0NJnynpIUm3TP2MP0PST0kaSfqvJz/bH5P0wOTjTNL7Jf3PknqSXizpk5K+cfI9fnhyHtw2+Tn8B0m/Ovnc8yWtS/quyfe6QdIXTj53p6Qzkr5Uuy0Rb5P0dnLkXI0wh1VO8PdMxf9W0i9I+iVJ/3Zq/9rkB/XCS0zwg5L+O0lHD3zvN0n6Xw/s+5jm+0L73VPxb0h601T8g5J+W1f/hfJnkv4XSc85cMwLJz+HjqRTkkpJJ+aRW1vmsA05cp4u3hxKeol2f3m9UlJ3av9PSfrrqTjT5Begdn/RPXjg+/y4pF+efHyvpFdMfe7U5OfQmRz3W5cZy52SfnEq/iZJHyVHztUIc1hlj8/jUx9vaXcyb5H06Ys73X1D0tPa/R/pQf/VJIlPm9l/NrOvmOx/gaQfnVzyOmdm5yQ9b/K95+WJqY+3LxE/m2a075f0UkkfNbP3mdm3XOKY50k64+5nr3ukhxN5Di+KnCPn6cQizKG736/d//n+lKTTZvb2qbc8Hpo6rpT08GQcL5B0y4Ex/oR2r/RdzOG3pj53r6Ri8vnnSfrEFYZ0qZ/robQhx6tY+HM1whzOu7n5Ue0mKEkys1XtXrZ65OCB7v4+d3+1pJu0+z/Td0w+9ZCkn3b341Pbirv/avXDvyabklYuBrb7Z783Xozd/T53/y7t5vdvJP365Ocx7SFJJ83s+BzG+2y1YQ7bkONFnKcNmkN3/0/u/tWTsbt2f+bS7ov/xVwy7b4l8OhkjA8cGOMRd/+mqRz+wYHPL7n7I5PPVdbTcjltyPEaLdy5uuhzOO/C5z9J+sdm9oVm1pf0v0l6j7t/avogM+uZ2Xeb2TF3H0m6oN3qT5L+b0n/1My+zHatmtk3m9mReSbyLHxc0tJkbF1J/0q7711Kkszse8zsxklVfG6yu5j+Bu7+mKQ/kPTzttuI2jWzr5nT+C+nDXPYhhwv4jxtyBya2Wea2ddPxruj3atyF8fyxWb2bbbbTP7Dkgba7Yl4r6QLtttsumxmuZl9rpl9yeTrfkHST5vZCyaPcaOZvXryubdJeqWZfYeZdczsBjP7wipya1OO12GhztUIczjXwsfd75L0P2m33+Ax7VZxr73M4d8r6VNmdkG7DWDfM/ked0v6J5L+vaSzku6X9H2VDvw6uPt5Sf9M0i9qt3Lf1O5lv4teJekeM9uQ9HOSXuvuO5f4Vt+r3fc6P6rd91V/uMpxX00b5rANOV7EeSqpOXPYl/Qz2m10fVy7/6v/icnnfkfSd07G8b2Svs3dR+5eSPqHkr5Qu42kT2l3Lo9Nvu7nJL1T0h+b2bp2fwl92SS/B7X7tsmPardB9IOS9v4KpyJtyPGaLOC5uvBzaL7bEAQAaCAz+yntNrd+T91jqUobcoxukeaQBQwBAEBrUPgAAIDW4K0uAADQGpVd8TGzV9nuUtb3m9kbqnqcukTPTyLHKKLnGD0/iRyjiJ7jouRXyRUf210L5OOSvkG7fyHyPknf5e4fudTxy8f7fvSWdGmQ0/eefcrdb7zU8XW71vwkqbO86r0je7ce0XD9jMbbm1b1WK/X9eR4cB4vPLqp7XODUDn2jy/56qn9vxDdfGxdg3M7YXLsLK967+jJZN/26YdjPRePrXj/5mN78eCJ8xqf3wozh5KUH1n1zo37yyqNnzynYj3W601nedW7x/bP1dH5WK+pR092/MZb+8m+T354K9Rzsdtb9aXlE3vxzvZZjYbVz2Gnou/7pZLud/dPSpKZvV3SqyVdeoJvWdV3vu0bk31vfPnbP32pYxvimvKTpN6Rk7r9O39kL77v13626jEe1jXneHAef+27/6jqMR7WNee4euqI/v5b/tFe/Mf/7W9VPcbDuqYce0fT81SSPvTGHwn1XOzffEyf8+++by++54furHaEh3fNOXZuPK5b/vUP7MWP/qv/q+oxHtY159g9dlIv/m/2z9VP/j+xXlNvvLWvn/mtz0r2fcftHwj1XFxaPqGXf+UP7sUf+Ks3Vj1GSdW91XWrppau1m71lyy/bWavt927Pt+9fXZQ0TAqc9X8pDTH8fbm3AY3I9ecYxvmcXD2UkvYNNo1PRfbcJ6Oz2/NbXAzcs05Fuvx57EIeK5O53fhzHiug5uBa57D0bCeOayq8LnUparkPTV3f7O73+Hudyyf6F/i8Ea7an5SmmNn+eAq/413zTm2YR77J5bmMKyZuqbnYhvO086xlUt8SaNdc475kfjzmAc8V6fzO3qyqjdkKnPNc9jt1TOHVf1kH9bUPTu0f7+OS7q5s64fu/FPk33zueB13a4pP0kqVl3nv3T/akHxu43/a7prznEpG+llK48mccNdc46SVF7y+d1Y15RjsVrqwpdtpzub/WS85jksS9P2sJvEDXfNOeZ5qWNH969sPZGX1Yxsdq59HnvS5vPKJG64a8rx9OCI3viprz+w9wNVjGtWrnkOR6umJ+7Yn7jR387nuVjVFZ/3SbrdzF5kZj3tLr/9zooeqw7R85PIMYroOUbPTyLHKKLnuDD5VXLFx93HZvbPJf2RpFzSW9z9nioeqw7R85PIMYroOUbPTyLHKKLnuEj5VfYmorv/vqTfr+r71y16fhI5RhE9x+j5SeQYRfQcFyW/RnRP9SzXbZ21uodRqbWlgb7y9k/uxX+0tHB/AXVVy9lQn99/KImjOZrv6BtO7v915nvzhfsrryta6o312c97PNn3qXqGUpnMXP3uOImjWeqM9dIbntyLH+ws3F8IPTsB5+6iwjOd3164P6a4Jt6Vdk4VSTwP3KsLAAC0BoUPAABoDQofAADQGhQ+AACgNRrR3NwGR/JtvXKqKfav8u0rHL2Y1sz05Ut5Ekdj5snCjBasufKm7gX989v+JNn3BzWNpSpmrl5eJHE0N3bX9c9O7c/j33bXaxxNNaxbqnvzdhJHUpam7cGcun1r8oKjT+nfveote/EPvempuTwuV3wAAEBrUPgAAIDWoPABAACt0Ygen5EXemy8UfcwKnVuvKLffOLlU/F9NY6mGk8VHd154aap+LEaR1ONG7KxvvvI03vxz2WxFoZbywp9xdK5uodRKTOpP7WgX8BWNF0olvWH5z9/Kp5P78Q8dTuFbrth/1x9vFNc4ejF44VpcD72AoZHM9ffXxkl8TxwxQcAALQGhQ8AAGgNCh8AANAajejxcUmjqx612La3e/q7e5+fxNGMvKNHhyeSOJqxSj1VbCZxJJtlprsHsW8YLEmlB2zsmbI+6usvTn/GVPyXNY6mGt2s0I3LG0kcSmmyrfzqxy2wJ4q+fvbMi6fi03N5XK74AACA1qDwAQAArUHhAwAAWqMRTRguqYh3u5yUSZq+l0zAFgOXNPI8iaPZLjN9eHhkKj5T42hm78x4TW9/6ssP7P1YLWOpSm6ljvV2kjiaXl7otrX9NW4+kgfrf5G0kg/1xcc+vRf/VT6scTQVMEl5xFfRfU8PVvQrn/ySqfhDc3lcrvgAAIDWoPABAACtQeEDAABag8IHAAC0RiOam0uZdjx2DWYjU//hXhJH07FSz+muJ3E0LqmY6kyP1np4c/eCfvjmdyf73lLTWKqSW6mjve0kjuam7gX90Kn9efxg90KNo6nGjfm2Xn/8w3vx2/PtKxy9gEopG8T7PTHteG9b//AF+3P4S735zGHsagMAAGAKhQ8AAGgNCh8AANAajenxWfdu3cOoVHd1pOd+xaN78WP/Md5tWc+Pl/UHpz93Kr6nxtFUY8kK3d49n8SRnClW9bazX3Zg72/WMpaqmKTuVF9PxC6KwjM9Xa4mcTRbZaa/GawmcSTZWFo6HSung47m2/oHR/YXLfx/59SnFfunCgAAMIXCBwAAtAaFDwAAaI3G9PjsBO/xWe6M9LknHtuLP9qJ1+OTybWUj5I4mvPlkn5/4zOn4o0aRzN7a9mOvurIx+seRqVW84G+5OgDe/Gf5IMaR1ONJ0dH9B8e+bqp+In6BlORJ8dH9ObHv3Yq/q0aRzN7blLZu/pxi6x006b3kngeuOIDAABag8IHAAC0BoUPAABojWb0+Lhpq+zXPYxKPb+7qX9/63v24vd2N2scTTUKN60Pl5I4mlJZcq6Wwf7vcCxzffPKTt3DqNTRbEffuPqxvfhNWbx8R2Wu05trSRzNoOjogQsnkziceLeRS5wvVvT7575gKj49l8eN9aoNAABwBRQ+AACgNSh8AABAa1D4AACA1mhEN5i3YAHDNijKTGd3lpM4mu2iq3s3TyVxJE+XHb1t/YYDe++vZSxV6VuuF3XXpuKzNY6mGke7O/r6U/sLUT7UjdfA7S4NRp0kjsQKqRtrfdRnOLezrN++9wum4r+Yy+PG+80EAABwGRQ+AACgNSh8AABAazSix2fsmc4VK3UPo1L3D47q2+7/hqn412scTTXG41xPnj6axBHN60Z6dSha8FwsVGqj3EniaDK5VvJhEkfTyUrdsLqVxJF4Lg2P1z2KamWZa3VtJ4nn8rhzeRQAAIAGoPABAACtQeEDAABaoxE9PqUybQa/Sen2sKsPPXxrEocUuP9FkjJzLeejJI6klGmr7NU9jEqV7lovx0kcTaFM68VSEkdzvLutb33uh/bi+7rbNY5m9rwrDW4s6h5GpXp5oduOnd+LH8rnk2+8ZwMAAMBlUPgAAIDWoPABAACt0YgeH5c08phrvlyUb2Q6+uf797F6fCNmzWl5rLU0Dio807nRchJHcmG0pLtOf9aBvX9Uy1iqMpLpybKTxNFcGPb17odfOhXP5x5I87SaDfSVK/ftxb+QDWocTUXinZqJlc5QX3j84b34bzvDKxw9O7FetQEAAK6AwgcAALQGhQ8AAGgNCh8AANAaDWlutvDNzcWSdO6zyyQOxyUf5kmMxXKyu6VvP/X+ZN+7ahpLVUxSd+rGpBH7R9e6Q33VqQf24ke682kanadVM31xv5fEkVinVOeGWIsyHpSr1LHOdhLPA1d8AABAa1D4AACA1qDwAQAArdGMHh83DcqgN+2csF6hpVs2kzgclzS2NA6mcNPGqJ/EkWyXXf3d1m11D6NSpUzr3k3iaE52NvSdJ9+zF7+7s1HjaKqx6a73D4ZJHEknL3Tj8XTePlHTWKqykg31RcufSuJ54IoPAABoDQofAADQGhQ+AACgNRrR49MKbvLpfpBgvSGSJDfZMEtiLJYTnU299sR7kn1vrGksVSll2gne47Nmpq9aypI4mu2yq78b3DYVP13jaGavdNPOKPav6C3v6W93nj8VPzKXx+WKDwAAaA0KHwAA0BoUPgAAoDUa8QZioUzrIW9etW+5O9TnnXp0Lz4d8N45MkkdT+OAIvaEXLRTdvXR4akDex+45LGLKpNr1YZJHM22l7pnuJ3EQNOYpHzq+TevV1au+AAAgNag8AEAAK1B4QMAAFqDwgcAALRGI5qb3aVB2YihVKaTlTrR20ricFxSeSAOKGIz7EUj7+jR4Ym6h1GprbKn9++8cCo+U99gKrJR9vXnWy+Zis/XOJpqHDxXRx7rd8had6ivOpX+YcEHaxpLVfo20ov7p5N4HrjiAwAAWoPCBwAAtMZ1Fz5m9jwz+//M7F4zu8fM/sVk/0kze5eZ3Tf5d2Gvm5MjOS6C6PlJ5EiOiyF6flKMHA9zxWcs6Ufd/bMlfbmkHzCzl0l6g6S73P12SXdN4isqZRqWnWRriJnl2GDkeA055uZa6w72ttwa0e8zs/yWs6FetvxIsjXEzHLM5Fqy4d7WoJ6tmeXoMo28s7d5cxbdnFmOI8/16OD43jbyvNKBP0szy28pG+n25dPJ1hAz/d2/U3b3tnktDnvdhY+7P+buH5h8vC7pXkm3Snq1pLdODnurpNccdpB1IUdyXATR85PIUeS4EKLnJ8XIcSY9Pmb2QklfJOk9km5298ek3R+QpJsu8zWvN7O7zezunbODWQyjUuR49RyLjY15DfW6HXoez+3Ma6jX5bD5nT8zntdQr9thc1w/O5+/HDmMw+a4cSZ+jttnYz8X2zCH6zW93hy68DGzNUm/IemH3f3Cs/06d3+zu9/h7ncsnegfdhiVIsfLm84xX1urboAzMJN5PN7ce8rNIr9jJxvzNvMlzSLHIye61Q1wBmaR49rJ+Dkun4j9XGzDHB6p6fXmUI9qZl3tJv42d//Nye4nzOyUuz9mZqckNeaNyesxqxxv6qzrh2+6ay/+q856JeO9HjObR3N515O4KWaVo0sae5bETTCr/HKVOp5tXe2wWswsRyt1PN9K4qaY5TweyzeTuClmlePJzoa+64b/shf/SacZV5xnld9qNtBXrtxX5VCv26xyHJRd3T+4eSr+eCXjPegwf9Vlkn5J0r3u/rNTn3qnpNdNPn6dpN+5/uHVixzJcRFEz08iR5HjQoienxQjx8Nc8fkqSd8r6e/M7OKCkj8h6WckvcPMvl/Sg5K+/XBDrBU5kuMiiJ6fRI7kuBii5ycFyPG6Cx93/wvpsn979orr/b5NQo7kuAii5yeRo8hxIUTPT4qRYyM6GU1Sx4q6h1Gpjkk35J7EWDyZXKv5MIkjOVOs6lef/rIDe+fzvvu8jD3Xk+OjSRxNk/uY8Ozkch3Jmv+XXYdRKNN6sZTE88AtKwAAQGtQ+AAAgNag8AEAAK1B4QMAAFqjEc3NpZu2i17dw6jUmWJZv3L+86biv65xNFUxWWFJjMWyMezrLx9+cd3DqJRLyQ0tY7Wn72pFA7dcJ7OdJI7k6WJVd575igN7f/OSxy6q1WygL1395F78m9l8bu3EFR8AANAaFD4AAKA1KHwAAEBrNKLHxyUNynjvQU97+vRR/cc3vWoq/kiNo6lIKdnAkjgaM1c/HydxJOU40+ZTK3UPo1Iu08g7SRzNjnf18Z3nJnE0Jimfev5Fm8Xj+ZZec/z9yb5/U9NYqtK1sZ7bOZfE88AVHwAA0BoUPgAAoDUofAAAQGs0osfHJHWD30SvWHWdu2N/jYLid2P1hkiSTPKuJzEWTObqrMW+MaIkZcFfb0yu7tSNny3YGjeStOk9vW/n+VPxhRpHM3tbZU8f3HnBgb2frmUsVRmUXX1ieNNU/MRcHpcrPgAAoDUofAAAQGtQ+AAAgNZoRI+PyzQoGzGU6pgr65ZJHFIZu7HHJHWS3olYjvQH+uoXfyLZ98nLHLvISo//f77So52dqUHZ0f07N0/FH61xNLNXeKaz49W6h1GpUqatsp/E8xD/2Q8AADBB4QMAAFqDwgcAALQGhQ8AAGiNRnQUu6Rx8GbDzoVMN7x7aS8+fSF2vlFl5lrOR0kcyfrOkv703pfWPQwc0tgznRuvJHE0mVxL2SiJI3GZioDzNq3wTOeLlSSeh9g/VQAAgCkUPgAAoDUofAAAQGs0osendNPWuFf3MCqVjV3LTxVJHI5JymPfpNTkylUmcSTd7li3njqb7HuwprFUxWUaeZ7E0WyNe/rAk7clcTS5lTqWbyVxJMvZUC9bfqTuYVSqmxW6rXcmieeBKz4AAKA1KHwAAEBrUPgAAIDWaESPj5Te+DEiK6Xu5jiJ43F5x5M4mq4VOtU7n8SRPLd/Qf/yM/4w2fePahpLVQo3rRdLSRxNWZo2B70kjma3V6uTxJGs2Eh39B+vexiV6mmsWztnk3geuOIDAABag8IHAAC0BoUPAABojcb0+JTR70nSNW0+t5fE4Zgki72Oj0sqphKL1sVUKNN6uVz3MCplStd8CXiaKs9KHVveSeJoejbW83pPJ3EkI2V6tOjXPYxKDb2jB0cnp+L5rFsUu9oAAACYQuEDAABag8IHAAC0BoUPAABojUY0N7ubhmV+9QMXWLEknfvM/Tqz+NP6xlIZlzS9GFy0zl9JI+/oseHxJI5kVOZ6eHjy6gcusK6N0xsjBmuKlXYX85temDHa4n6StGwjfV7v8SSO5EKxrHevf+6BvZ+uZSxV2Sp7+sDmC6fij83lcbniAwAAWoPCBwAAtAaFDwAAaI1GNCi4pKIMXoMtlSo+ayOJ4zFZYUkcTemm7aKbxJHslF19dPO5dQ+jUi7TTtlN4miKItPZ9ZUkjmbbu7pneNNUfP4KRy+eUqatsnf1AxdYLyv0/P6ZJJ6HeM8GAACAy6DwAQAArUHhAwAAWqMZPT5uGhSNGEplvDSNtnpJHI/LM0/iaEo3bY77SRzJsMz16OaxuodRqaF39ODghiSOxgvT4PxSEkez2wPTT2Isls2ip7vPv2Aq/sBcHpcrPgAAoDUofAAAQGtQ+AAAgNZoxpvbJpnF6wdJjEyd090kDsckdcs0DqbUgXV8giV5pDPQ1954X7Lv3TWNpSodK/Wc7kYSh5O58pVxEkczKLv65OCmqfjjNY5m9vo20kuWnqh7GJUal5nODFaSeB644gMAAFqDwgcAALQGhQ8AAGgNCh8AANAazWhulpQFb27Oh9LRB9I4pGAL+h1Uumlr3EviSNbyHX312sfqHkalTK5+NkriaLLM1V8aJnE0hWc6O15J4kiek4/1fUdPJ/u+v6axVKV00/pw/gvCxjpTAAAAroDCBwAAtAaFDwAAaI1G9PiYXN2sqHsYlcoHrqOfHidxSAHXgptWumln6oa60Xp8BmVX9w2ee2Dv/bWMpSomV9eKJI6mLE3DQTeJoylk2iz6SRzJ2TLXb2wcrXsYlSrKTOe3lpN4HrjiAwAAWoPCBwAAtAaFDwAAaI1G9PhI8dZgOMhKV2djlMThuNJ1fEKmaBqVeRJHsln29P6NFx7Y+xd1DKUyLtOg7CZxOEWm4mw/iaPZGPb1l4+8KIkj2Sz6+uuNzziw9wO1jKUq7qbRKE/ieYj3bAAAALgMCh8AANAaFD4AAKA1GtPjk0VsCJlSdjLt3NRP4nBM0vQ9gQK2TrhLO+NOEkeyNerpfU88v+5h4NBcntyfK9iJKqmbFzp19MJe/Ok81lpwY890Zrha9zAq5S4VU/1n83o9DfjbFwAA4NIofAAAQGtQ+AAAgNag8AEAAK3RiObmzFzLndHVD1xgnkuDo1kSh+OSyuALGLppmDQ3x+vgNgs4cS1jHVf3+CCJo1nKx3rp0dN78Qfz8RWOXjyFZzo/Wqp7GJUy2/39Px3PA1d8AABAa1D4AACA1jh04WNmuZn9jZn97iQ+aWbvMrP7Jv+eOPww60WOi59j9PwkcoyQY/T8JHIkx/rN4orPv5B071T8Bkl3ufvtku6axFdkkjpZkWwNc+gcs7Fr+elib8vGjXvP/dA5NtzM8jPzva1hDp1jUWY6t76cbA0zg9cbVz8b7W3WrGa0mZyneV7q5LHNvS3PywqGet1mkuN20dXfnb1lb9suulf/ovk5/O8MK7XSGSZbwxw6Ry9Mo43e3ubFAtyk1Mxuk/TNkn5xaverJb118vFbJb3mMI9RN3KUtOA5Rs9PIsfJxwudY/T8JHKcfEyONTvsFZ//U9K/lDT934mb3f0xSZr8e9OlvtDMXm9md5vZ3YNz24ccRqVmkuNouFn9SK/fTHIsNhqb43XnJ6U5ji9sVTvS6zebObzQ2DmUZpTjxtnG/gXp7M7T8/HOU+nAa+q5eDlO57dzbqf6kV6/2bzerNfzenPdhY+ZfYuk0+7+/uv5end/s7vf4e539I837nK6pNnm2O01854rs8wxX2tejofNT0pz7BxdmeHoZmOmc3i0eXMozTbHtRONektEUgXn6bF456l04DX1eLwcp/NbOt7MP2Wf6evNkXpebw6zjs9XSfpWM/smSUuSjprZr0h6wsxOuftjZnZK0ukrfhdJkid/y98gM8vRSqm7Pk7ihpjdPJoka9xNSmd4nu6uObHSHSVxA8w0x4aaWY4D7+oTOzclcQPMdA7H40xPnT2SxA0w2xyLTE+uryVxA8wsx+1xV/c89dyKh3tdZvt6U8Nr6HWfKe7+4+5+m7u/UNJrJf2Ju3+PpHdKet3ksNdJ+p1Dj7Im5Lj4OUbPTyJHBcgxen4SOYocG6OKEvlnJH2Dmd0n6RsmcTTkuPii5yeRYwTR85PIMYqFyXEmt6xw9z+V9KeTj5+W9IpZfN8mIcfFFz0/iRwjiJ6fRI5RLGqOjbhXV7Dz3yUAACAASURBVOGZzg6a16g2S25S2cuSOByT1G1cj89MuaRRmSVxJKu9gb78BZ9K9n2inqFUpnTT5rifxOG4qRxlSRxNOc60eWY5iSM53tvWtz7/w8m+D9Y0lqpY7lo6NkjieYh1pgAAAFwBhQ8AAGgNCh8AANAaFD4AAKA1GtHcXLppMG7EUCpTdk0bt3STOBxXuoB5tM5fTfq3szKJI9kc9vXeh15Q9zAqlzVoBdEqWObq9MdJHFIZ7Rm4b6vo6W/OPa/uYVSq1xnr+SfP7sWPdcZXOHp2uOIDAABag8IHAAC0BoUPAABojcY01hQBF9hKuJSNPImxeFzpgnfhpnE7k91z5OrHLbCuFXpu70ISR+MuldMLbYY7USei5iVpXGZ6crueu5fPS1FmOrO9ksTzwBUfAADQGhQ+AACgNSh8AABAazSmxye3wG/WSsoKV/9CmcQhBW/VkoLe1HLCXMqGdY+iWpmVWskHSRyNmZTlRRKHU5pskCVxJDf31/UjL353su87ahpLlayG3/1c8QEAAK1B4QMAAFqDwgcAALRGY3p8wq/jI8nKoH09F5nSHp+AU+oyjafXR4mWpEudnboHUa2x5zo9PJrE0bhLxThP4mi6SyPd8tIn9+KnlkY1jmb2Cs90rli5+oELbKkz0medfGIvfqAznznkig8AAGgNCh8AANAaFD4AAKA1KHwAAEBrNKK52WVzuzlZbVxSeSAOyLKgibVEueS68LJYTaIHmVz9bJzE4bjJC0viaLpZoVvWzu/F92axbjZ7brys33vy8w7s/YtaxlIVU7p48bzO0uDVBgAAwD4KHwAA0BoUPgAAoDWa0ePjpsGoEUOpjOem8WqWxCFFv9msXEudcRJHstQf6bNf8kiy78GaxlKV3b6CMonDKUx2tpfE0WyPevrgw7cmcSSlm7bGsXI6aLvo6qNnb0rieeCKDwAAaA0KHwAA0BoUPgAAoDUa0Vjjvvt+ZmRWuvIdT+JwzJV1PImjMXMtTd1Iz4LlWMo0KBrxslAZ1+4NIKfjiIK/pO4+F5fiPheX85E+69gTyb531TSWquRW6mhvkMTzwBUfAADQGhQ+AACgNSh8AABAazTizXwzV57N5729uljh6p0bJnFE0d5nPyg311p3kMSRjIpMj507WvcwKuUyjTxP4nBKKd+2JI7G3TSaWv/NgzU1rY+W9J8ffkndw6hU6abNqfWX5tXryxUfAADQGhQ+AACgNSh8AABAa1D4AACA1mhEc7Nk4RrTDrLC1dmI39wcnSttwIs2i3nmOra6XfcwKpXJtZSNkjgaK6XOliVxND427Ty5nMSRdLJCNx9Zr3sYlcrMtdodJvFcHncujwIAANAAFD4AAKA1KHwAAEBrNKLHpyxNm9u9qx+4wDw3jY/0kzgas3QBQ4uXokzp+9DRUuxmhW5c2ax7GJWL2NfzDNFOzoMySUtlGgcyKnI9cv5Y3cOolMs0Tm4YzAKGAAAAM0XhAwAAWoPCBwAAtEYjenwkKctiv+dedjNt39xL4mjcpbLMkjgeP7DWRKwkt7f6+vCHXlD3MCo19kxPj1aTOByTPPckjmZtaUd/77M/vhf/wdJOjaOZvcxcy73R1Q9cYGVpurCzlMTzEPAZDwAAcGkUPgAAoDUofAAAQGs0osfHzJXnAW8mc0Dw25FJMpWFJXE0ZlJn6sZHEdcqaoOiBf/ni9i6NG1n3NVHz9ycxJHkWaljwfqWDnJJRTn/ex8Gf2oAAADso/ABAACtQeEDAABag8IHAAC0RiOam90tWfguKs+Cd8KWkg+zJI4mk2s5HyVxJFZKnfXYz8WOlXpOdyOJwzHJ8zSO5mDzb57Fm8dory8HlWWm7UEviech9iscAADAFAofAADQGhQ+AACgNRrR4yNJRRHwTehppvR99qjpBp9HM1cnK5I4Eiuk7nrsOXRJxdTqfrFmcMIlG6dxNKMi16PnjiZxJC7TsIyV00Fmrl53nMTzwBUfAADQGhQ+AACgNSh8AABAazSix8d9fn+/Xxc3qehaEofjShML2Ffgbiqn+0OiTaRLndj3RdTYcz09Wk3iiIK1nz1DWWTaurCUxJGUbtoexbrx6kHupuGok8TzEOtMAQAAuAIKHwAA0BoUPgAAoDUa0eMjxV3WJhE9yUxSr0zjgMYeNDHt9oUk678E5JIGZSeJsXi63bGed8uZvfjpbqwTt5OVes7KZt3DqFSWlVruD5N4Lo87l0cBAABoAAofAADQGhQ+AACgNSh8AABAazSiudlMsjk1NdXFM2l4xJI4Istjz+PYM50fLiVxJGVH2r45druvSepamcTReC4NT5RJHI2Z1M2LJI5kXGZ6amv16gcusDxzHVveSeJ5iPWqDQAAcAUUPgAAoDUOVfiY2XEz+3Uz+6iZ3WtmX2FmJ83sXWZ23+TfE7MabB3IkRwXQfT8JHIkx8UQPT9p8XM87BWfn5P0h+7+WZK+QNK9kt4g6S53v13SXZP4itylssiTrUFmk6Pt9k9c3Bp2b8uZ5Ci7xNYcM8mxdNPmqL+3lc2ZyJnklw2ltQfTrUFm81yUNPJsb2tYR9NsnouSbGx7W8PM7Lm4NerubdGeiyd7m3rtC+5OtgaZSY7DUa6HTp/c24aj+fzuv+7Cx8yOSvoaSb8kSe4+dPdzkl4t6a2Tw94q6TWHHWRdyJEcF0H0/CRyFDkuhOj5STFyPMwVnxdLelLSL5vZ35jZL5rZqqSb3f0xSZr8e9OlvtjMXm9md5vZ3cV6Y5flnl2O2y3I8UL8HEfnt+c36mdvZvmNd+LP4c7ZwfxGfW1m91zciD+P4/Nb8xv1szez/DbPjOY36muz8L/7D1P4dCS9XNKb3P2LJG3qWV6ClSR3f7O73+Hud+RHGvsne7PLcbkFOR6Nn2P32HJVYzyMmeXXWYo/h0sn+lWN8bBm91xciz+PnWMrVY3xMGaW3+rJblVjPKyF/91/mMLnYUkPu/t7JvGva/eH8YSZnZKkyb+nr/aNzKROd5xsDTGzHLNCWjrre1tWXO0r5mZmOcollba/Nad5YnY5Siple1tDzCy/sittnbJka4jZvd5odx2fi1tjMpzleVpK2cD2NjVnea2Z5TgeZ3rq7JG9bTxuxB8pzyy/C+NlvfvJz062hpjd78XM1V8a7m1Z09fxcffHJT1kZp852fUKSR+R9E5Jr5vse52k3znUCGtEjuS4CKLnJ5GjyHEhRM9PipHjYVdu/kFJbzOznqRPSvrH2i2m3mFm3y/pQUnffsjHqBs5kuMiiJ6fRI7kuBii5ycteI6HKnzc/YOS7rjEp15xmO/bJOQYQ/Qco+cnkeO8x1KV6DlGz09a/Bwbca8uKd59Vp7BJSs9iSPyMvZEuptGU+tMeXPWDpkJ77sGL965+oELzKWkPyvkUzGXiiNlEsdjKpK+nljPxVGR6bH1I3UPo1LupvF4/q+njegGAwAAmAcKHwAA0BoUPgAAoDUofAAAQGs0prm5DN4UKyloF+UUl1RYGgdz8caI03Ek/d5It9+Wrjv26ZrGUqUi2LwdZIXUWc+SOJosK3Xk6P4tZJ7ImrNK4yyYpHxOC/rVxUvTcKubxPPAFR8AANAaFD4AAKA1KHwAAEBrNKLHx8y11B/VPYxKZYWrf6FMYiwgkzLzJI5kXGZ6aquRd72eqdyCP/9KqbNhSRxNOc504enVJI6kKDOduxD8uWiuvF8k8TzEOlMAAACugMIHAAC0BoUPAABojUb0+Libdgbdqx+4wMqOaedEnsThZJJNv18bsaz2A2v3BGsVKUa5zjx2rO5hVMokZVMTF/CZKM+k0ZoncTguaZilcSBmrv5S7N5XjTOVT/eTeB4iPh0AAAAuicIHAAC0BoUPAABojUb0+Ejzu0dHXcZrrtNfs/9+7fhPg70hLUlyWXJvmXg5mrmWOuMkjsRGpt4TjXlZqITJ1c9GSRyNScqKNA4p3tTt6eWFnnf8XLLvIzWNpTKm9OSc04nKFR8AANAaFD4AAKA1KHwAAEBrUPgAAIDWaEQXo5em0U4jhlKdwtQ5003iaMykbm+cxNFk5lrpDpM4kmwkrT5a9yiq1bFSJ7pbSRxRyEULDwqc4+4Ng1evfuBCc3k+/z+ICXzaAAAApCh8AABAa1D4AACA1mhGY40rZM/LtGwkLZ22JI7GzNXvxV3cT5JyK3W0t5PEkWRjafnpePM2rZRpp+wmcTgu5YO4N9OVtLvY3XR/SLBpLN20M2rGr+jqmKyc/wqGXPEBAACtQeEDAABag8IHAAC0RnPeQAz2/uwlBc/RzNXJiySOxixd9yXaWkVuUtG9+nGLLJNraarJLgvZACOVnZh5XWQjU+/xThJHstYb6KtvfSDZd09NY6kO6/gAAABUisIHAAC0BoUPAABojWb0+JjC9790dlw33LPfV/DgTrz3301SZmkcUch1XybMpXwY79ycVsq0VfSSOByTPE/jaKyUOtuWxJFsDPv684dfXPcwqmWSOmUazwFXfAAAQGtQ+AAAgNag8AEAAK1B4QMAAFqjMc3N1gnWmXaQH2i+C9g/6pJKT2MslqIvXXhRfvUDF5i7aTTV+esesPNXCtnQ/AyBX2S6eaFbjl5I9n2kprFUJnNl/SKJ5/Kwc3kUAACABqDwAQAArUHhAwAAWqMZPT4uqYz9hvR4xfTkF+7f/XH8N/HydTeNihb0TgRmhdTZrHsU1SplGpSdJA7HpWxgSRyNFVLvQhpHMhx39OCZE3UPo1JmUqdXJPE8cMUHAAC0BoUPAABoDQofAADQGo3p8fFR7BqszKXBCU/iaNxNw2EniaMZl5nODZaTOJKyK23fHLAhZIrJlZkncUQ+pzVR6uImTbVqKdrLjbs03GnGr+gqeQ39vbFetQEAAK6AwgcAALQGhQ8AAGiNZryBaJKi36vLlN47J9j70YghG0prD9U9imqVMm0X3SQOx6V8J/Y6Psqk8Woah+JWS//LPHlpGg/zJJ6HaKcKAADAZVH4AACA1qDwAQAArUHhAwAAWqMZzc1SvNWnDjBPb6JnEZsNFXPRwmku02hq9UmP1hibSePlYDkd4G4qPUvicEzybhqH41I2SuNQDv5BTEQu+ThL4nngig8AAGgNCh8AANAaFD4AAKA1mtPjE1x3w3XLX4z34ic2or0hvcuiNi9NlG7aGnWTOJKyI+08J/YcStLYg/+fzyWVB+JgsrG08oQncSRZVmr1yE7dwwgp+LMfAABgH4UPAABoDQofAADQGo3o8bHM1V0Z1j2MSpW5aXAsT2IsIJfGRZ7EkXhHGp4MfsNgSR0LnmMmFSuexNF4Jo1W0jgSM1c3L65+4CIzyXJP4nkIdqoAAABcHoUPAABoDQofAADQGs3o8TFXvx9sEYaDTCq6lsTRmLnyvEzicEzqTL/vHmwebSx1z8b+/1BupY52tpMYC8gk78R9TS3Guc6dXa17GNUySRk9PgAAAJWh8AEAAK1B4QMAAFqDwgcAALRGI5qb3U3jcX71AxeYudQZeBJH424ajfIkjsbk6mZlEkeSD6TjH697FNXKzNWfuqNlFvLJKNkojcMJfiPWvFPo+InNZN+naxpLZQrJNztJPA9c8QEAAK1B4QMAAFrjUIWPmf33ZnaPmX3YzH7VzJbM7KSZvcvM7pv8e2JWg60DOS5+jtHzk8iRHBdD9PwkclyEHK+78DGzWyX9kKQ73P1zJeWSXivpDZLucvfbJd01ia/I3TTY7iZbE8wyR7lk5f7WlPejZ5qjJLntbw0w8/wkFW57WxPM9LloUtFLtyaYaY4yFcr2Nm/Iynezfr3JB7a3NeH1ZtbPRc+ksr+/NeEmpbPMsRh0dO7Tx5OtCWY6j6Up2872NpXzeS4e9lTpSFo2s46kFUmPSnq1pLdOPv9WSa855GPUjRwXP8fo+UnkKJHjIoien0SOUsNzvO7Cx90fkfR/SHpQ0mOSzrv7H0u62d0fmxzzmKSbLvX1ZvZ6M7vbzO4uLmxe6pDazTLH0SB+jk2cx8PmJx2Yx/PblzusNrOcw/FO8+ZQmm2OW2cH8xr2NZnpc3GrefM46+dixByT/DY25jXsazLTHDfrmcPDvNV1QrsV3osk3SJp1cy+59l+vbu/2d3vcPc78qPNvB/JLHPs9uPn2MR5PGx+0oF5PLZcxTAPZZZz2Flq3hxKs81x5US/qmEeykyfiyvNm8dZPxcj5pjkt7ZW1TAPZaY5rtYzh4d5q+uVkh5w9yfdfSTpNyV9paQnzOyUJE3+PX31b+XKOmWyNcQMc5Ss9L2tQWaWo7tUuu1t3ow0ZzqHkpSb720NMbscM6lYtmRriJnPYwPNLEc70FPYkFN1pnPomTQ8sr81ocdHs8zRpXw7S7aGmOl5Ot2LNq/z9DA/yQclfbmZrZiZSXqFpHslvVPS6ybHvE7S7xxuiLUix12LnGP0/CRyJMfFED0/iRwXIsfrXrnZ3d9jZr8u6QOSxpL+RtKbJa1JeoeZfb92f0DfPouB1oEcFz/H6PlJ5ChyXAjR85PIUQuS46FuWeHuPynpJw/sHmi3AgyBHBdf9PwkcqxhOJWInmP0/CRyrGE416wR9+qS1JCVNKpTdKX12/IkjsZMyvMyiSMqG7J+TxWysbT8VGN67CrhLg3KThJHZHO671FdrJS6m2kcysF7kQVkY6n/tCXxPDSmWwoAAKBqFD4AAKA1KHwAAEBrUPgAAIDWaERzs5mUd6J34h1YYCtgf6y7VBZZEkcUNC1Jko1d/bNz6jCsics0LvMkDqeU8p00DscO3EQ32jRmUrEaceL2WSl1NzyJ54ErPgAAoDUofAAAQGtQ+AAAgNZoSI+Pq9uN3ePjmTRaS+OIIve/XBStlWBa2TFt39iIl4XKlG7anGoOCbkgpSn9b23AFD2Tyn4ah5K5fDn270UrpP4FT+J5iHaqAAAAXBaFDwAAaA0KHwAA0BqNeDO/LE3b272rH7jArJQ622kcjZmUZfFvUppZ3E6msiNtPyf2/4dcUjHV1xNxNs3TGz6GPGX9QE9ItBxNsk60pFLZ2NU/WyTxXB53Lo8CAADQABQ+AACgNSh8AABAazSix0cylePYNZh3pMENnsRYPGZSHriPKSuk/rnYfQVtuFeXK13XJuKMei4NTpRJHIq5sm7AZtADrJz/2Rm72gAAAJhC4QMAAFqDwgcAALQGhQ8AAGiNZrTYuuRFvAbDZwjep+YulUWexOG45NM3tQyWo2fSaCX2c7F009Y4+E1KpZA3Jk2Y0hyD5dvplHrOifVk3wM1jaUqnknFcpbE88AVHwAA0BoUPgAAoDUofAAAQGs0psdHwRcwlEvZKG5viCSpNBWbnSSOxiWNyiyJI/FMGq/UPYpquZuG0wsYBuzxMaU38IyX4W5+nQ1L4khMniyWGpKZyo4l8TwErzYAAAD2UfgAAIDWoPABAACt0YweHyles8QB+Y504mP779c+slPjYKriSvt6gs9pROZSPqx7FDg0P9DzEvC5aGNp6WlL4kiKMtOF7aW6h1E5z+bfgcYVHwAA0BoUPgAAoDUofAAAQGs0p8enBeZ1H5L6mGwc+OY5EzGz2rXbNxF87ZA2MMnzNI7GXMpGaRxJWWTaOBt8US2plps6hv9VDAAAcBGFDwAAaA0KHwAA0BoUPgAAoDWa0dx8cOE7oMGC9VC2TinToOgkcTillA88iaOxUuqtexKHUphsM7/6cQvMTSr6lsTzwBUfAADQGhQ+AACgNSh8AABAazSjx0cmKwK+zz7FSqm7Gfj9aGm3+cUPxAHl0VZKm+Idaedk7P8PlaVpfdBP4ogCn6aSJCtc/fNFEoeSubwX8RfFFJPKjiXxPMR+hQMAAJhC4QMAAFqDwgcAALRGQ3p8FLYf5CIrXL3z4yQOKWi/xEUmKZtqngiXbSl1doKemxOlmzZ3ekkcTVZI/XNlEkeTjV1LTw2TOJQWrG/nJhW9NJ4HrvgAAIDWoPABAACtQeEDAABaoyE9Pi7Pg70/e5BJZS9L4oiirx0ik/KsTOJIDvaGRFSWpp2tXhJH5FnMvC4qu5k2blvaj++J9f/4bGhaeaghv6KrYlLZZR0fAACAylD4AACA1qDwAQAArUHhAwAAWqMhnVMmC9pgeJHnptFalsTh+G5D3nQcjckPLGAYK0k/2GwYUWkqdzpJHI67OoMyiSPKoi4EOxHyZtZTPJPGK2k8D1zxAQAArUHhAwAAWoPCBwAAtEZDenxcngV/r3bs6p8dJ3E05pIVaRxN6aatUTeJI/FMGq3EyukZSpPtZEkcjZVSPnWz2Yi9ImUu7RzPkjgSt3g5PYNJnqfxPHDFBwAAtAaFDwAAaA0KHwAA0BrN6PExScF7fJRJRT9L4ogi9hJMczcNx50kjsQUfw7lUjbd4xP8pQeLKRtL/XN1j6J6dbzeBP31CwAA8EwUPgAAoDUofAAAQGs0o8fHtbtoQWBlbto5kSdxOC6pPBAHZBEXKLqolDo7gfPTZI2bQRqH41I2KpM4nEwaL1sSR1J2pMGJukcRU7BTBQAA4PIofAAAQGtQ+AAAgNag8AEAAK3RjOZmk9SN2GG4L98pdfzjm0kcUVYEbNqeZlKelUkcibmUDyJ2wqaycbCJO2B3IUpP4mg8k0ZraRyKSd6M39CVsVLqbKXxPEQ7VQAAAC6LwgcAALTGVQsfM3uLmZ02sw9P7TtpZu8ys/sm/56Y+tyPm9n9ZvYxM/vGqgY+S+RIjouQY/T8JHIkx8XIMXp+Uuwcn80VnzslverAvjdIusvdb5d01ySWmb1M0mslfc7ka37ezHJdTebKekWyzdmdqjhHG42UP/zk3maj0SzH/2zcqarn0SUb7281LJp2p6qeR7m6Wbm32XyTvFNV51e4eutFss3ZnZrHeTra3yKepw1wp+Ywj9l4f5vzPN6pOeT3jG2+7lTFObqkMt/f5pXiVQsfd/8zSWcO7H61pLdOPn6rpNdM7X+7uw/c/QFJ90v60hmNtTLkKIkcG59j9Pwkcpx8TI4NzzF6flLsHK+3x+dmd39Mkib/3jTZf6ukh6aOe3iy7xnM7PVmdreZ3V1c2LzUIXWbaY7DcrvSwV6n2c7jVvx5HJ9v3DzONL/RMP4cFpvxcxy2YR63G5cjr6f7Gj2Hs25uvtRfTV7y6pW7v9nd73D3O/KjqzMeRqWuK8detlzxsGbq+uZxJf48do4tzDxeV37dXvw5zFfj59hrwzwuL0yOvJ5O72zAHF5v4fOEmZ2SpMm/pyf7H5b0vKnjbpP06PUPr1azzdFdPhzubfJGrJUy0xzNpWy0vzXkXp4zzTEzV78z3tuy+pOc7RwWru6FYbI1wOzP06nekPqnUFIFrzdW7m8RX2+ykbT6aLm3ZXNvm3yG2c6hSZ57sjVABTnub/NacOp6C593Snrd5OPXSfqdqf2vNbO+mb1I0u2S3nu4IdaGHMlxEUTPTyJHclwM0fOTguR41XUhzexXJX2dpOeY2cOSflLSz0h6h5l9v6QHJX27JLn7PWb2DkkfkTSW9APuPvc/C7lW5EiOWoAco+cnkSM5LkaO0fOTYud41cLH3b/rMp96xWWO/2lJP32YQc0bOV7yeHJsmOj5SeR4mePJsWGi5yfFzrERdwIxk/JOzHtXXeTjQsXT+38Z2OBi+PqVUr6TxhHl87qhTB0yU7HUiJeFSoW7r9NBLtmoTOJwTCq7lsShmFR26x5EtayQeuuexPMQ/ekPAACwh8IHAAC0BoUPAABoDQofAADQGo3pYszywA2jkizLlK0d2Y834tWcVkrdTU/iaEo3bY16SRyJZ9JorTEvC7heJnk3S+JorJQ623Ffb1xSsJeXZ7IDf2jQ8AUMAQAAFg6FDwAAaA0KHwAA0BqNeTPfor+XmWWylak7e2/FqzlN6fvsEafUZRoWeRJH4mbponBBNeTGpJVxM5V5lsTR2Ni19PQoiSM5+HoakefSzklL4nmI99sXAADgMih8AABAa1D4AACA1mhGj4+5LPqb7pJUBs+xlPKhJ3E4fmDtnmBTau7KhxEn7oBg83aQuSsbFkkcjZWu7sYoiUNxKRvF681KuNTZSeN54IoPAABoDQofAADQGhQ+AACgNRrR42NS/B6fLJOtrezH52LWnFZc/ZhFZubq5UUSR2Kl1NkKPol+YH2UWFO4y6VsXCZxNDYaq/PY2SQOxVvwelpI3Q1P4nmI+dsXAADgEih8AABAa1D4AACA1qDwAQAArdGI5mZJyrKA3XfTylK+sZXE4ZjSG1wGX3srpNKVDWJ3VJpLne00DsekspsncTQ+Gqt4/HQSY7FkY2n56TKJ5/K483kYAACA+lH4AACA1qDwAQAArdGIHh8zqZMF7HmZ5i6NhmkckLeglM5CNoVMmOTd2JNY16Jpcxd7GmWZKev39+PoN/QMyDNptGJJPA/BnxoAAAD7KHwAAEBrUPgAAIDWaEaPj1zdTtQ32i9yqfQ0jsYOvEcb9C330oMmJklmcgucn7R7A8+RJ3FIRdTEJlzy8TiJI7FS6m7WPYpq7eboSTwPXPEBAACtQeEDAABag8IHAAC0RiN6fNrAi1LFhQv7sQdct8ilbJTG0bhMxVSPjwdrZHJJnsfK6VLm1UtQG5eyYZHEIUXuRzOp6NU9iGpZ6epsl0k8D1zxAQAArUHhAwAAWoPCBwAAtAaFDwAAaI1GNDe7TKNxXvcwKmVZpmx5ZT/ejldzWinlw/kvRjVP7tJw6lyNdq9Z0/waDOtinp6bEe85a6UrG4yTOJw8U3ZkbT8eBHtNdamzU/cgqlfHuRnsTAEAALg8Ch8AANAaFD4AAKA1GtHjU7o0GDViKNXp96SXPH8//njMlalC9hIkTGUZ+E6s7sqGAZuzDoh+nnpmKvudJA6nKFVubiUxFks2KtV/fCOJ5/K4c3kUAACABqDwAQAArUHhAwAAWqMZjTVuKooW1GCRb6g3j1v2fAAACmpJREFUEXHtnmnuUjl9k9JorSKlK9sZXf24ReZSVqRxRJ7Hfk31slS5vr4fB7zxcxl7eTvJXVZ4Es9D7GcGAADAFAofAADQGhQ+AACgNZrR46OAvRIHlaWy9e0kjsZNKnqWxNGYSdnUzZ2itW1Z6cp2xlc/EI1nwV9ULc+Urx3djzdi/T/eSqm7EXsOPc9UHOkn8TzEOlMAAACugMIHAAC0BoUPAABoDQofAADQGo1obnaXinHwlZrKUtreSeNgrJQ6A0/ieFxZViZxJJ6Zyl4jXhYq5AduUhprDiXtLgw3LpM4nCyXHT2yH2/F+x3iebC/njjIDjQ0zyldrvgAAIDWoPABAACtQeEDAABaoxlv5rvJx9FrMJPyPI2BhjGXLGD/2TMEbHlJmMk7WRJH4+ORisefSOJIrJD654I/F12yokzieYhebQAAAOyh8AEAAK1B4QMAAFqjGT0+irnMRCIz+VIviaMxd2UjT+KIPOLdV6cVMeftot0+pjQOqYya2C7rdJTf+Jz9+MnG/DqbCXOpsxN8DktXtj1K4nngig8AAGgNCh8AANAaFD4AAKA1mvGmqEsqgvdNtICb5FkaR+NuKsosiUMpCmXrm3WPonqxWyd279U1Cn6vLsukfi+Ng4l+ry43k0/dG9DntN5UvDMFAADgMih8AABAa1D4AACA1qDwAQAArdGc5uboNynNMvlSP4mjMd+9sd50HI1LGo3zJA4n+MJ3UtzFNRPxXmJSeaZybSWJI/FcGq7Fbm6WHfgjmDmlG+tMAQAAuAIKHwAA0BpXLXzM7C1mdtrMPjy17383s4+a2YfM7LfM7PjU537czO43s4+Z2TdWNfBZIkdyXIQco+cnkSM5LkaO0fOTYuf4bK743CnpVQf2vUvS57r750v6uKQflyQze5mk10r6nMnX/LyZ5boqk43Tbc7uVMU5upl8ubu/zWmhpil3qvJ53O2duLjV4E5VnKNJMvP9bYaDfxbu1Byei8qzdPv/27uXELnSMg7jz1t9C5rILCIqkyy8DN5wIYQBNzowIiKjceFidCPMQgUFlwqCgjArdy4HL0EQB5eDOqJuvCCZcRAUHQ3EiZIwkzFX00m6q+vyuujqdJ+eSlpTVadOfef5QZF6z/lS/f1T51S/OXycqtcpajhO5+wUsz5OE6I72H3UfzqeYuafqZCHlncf9Z6Mp5j1eziAtf8MK4+anaKGczGXOncedTnwJ2Xmb4Cr+7b9IjP7o/I0cGz0/CTwdGZ2M/MccBZ4eIrznQkzAmZsfMbS84EZR6UZG56x9HxQdsZptFhPAM+Onj8InN+z78Jo22tExOci4oWIeGFw8+YUpjFTE2fs9Rv/NQCTZ9wqP2P/xu0ZT3EiE+fbGjQ6H3ic/m/vYxs+b/qNPlYnz9dtwe/F3nyO04kan4j4GtAHfrizacywsRdZM/OpzDyRmSeWDh+eZBozNa2MK8uvn9UUJza1jKvlZ1x+w+vGDZm7aeVbXWpmPvA43ePg97ENnzfLzTxWp5ZvrQW/F1fmc5ze9318IuKzwGPAo5l3FnRcAI7vGXYMePngV0uy07z7akw145zuV3CQ6b6PzTTNjBGwujyo1PM21fcwh7DZnfocJzXdjMBwX90A0824b51dQ+5bVPrnzVQ/a4bJ0lYz3re9pn2cdnqDSl2H+7riExEfBb4CfCIz915vfAZ4PCLWIuKtwEPA85NPs35mNOMiKD0fmBEzLoTS80E5GQ+84hMRPwIeAY5GxAXgG2yv5F4Dfhnb/+U9nZlfyMy/RsSPgRfZvgz2xcwcjH/l5jCjGVmAjKXnAzNixoXIWHo+KDvjgY1PZn56zObv3mP8k8CTk0yqbmYcO96MDVN6PjDjXcabsWFKzwdlZ2zGd3W1QAyTztagUhep0Fg7hgnd3nKlLkn2+vQvvjrvacxcid8jV5FJbHQrdXE6weDQcqUuSQyStatb857GjMW+hZL1vId+ZYUkSWoNGx9JktQaNj6SJKk1bHwkSVJrNGNxc87li0nrN6z9S+bqlRANvDHcNOUw6G6uVOqSRKdD5/CR6sYb85nLzCR0esNKXaI6v/RxHqI/ZOXaRqUuSlLmovQGKPvMkCRJ2sPGR5IktYaNjyRJao1GrPGJIaysl92DZUAuLVXq0sQgWb3erdTF6XfIa6uVujiFr0WLwZCV65uVujgJ0etX6uIMk7i1UamLkkmn2z943AKLTKLbq9R1KPBTW5IkaTwbH0mS1Bo2PpIkqTUascZn7XKPt3//YmXb2TnNZWY6weDwaqUuzq0NOP3n3To37j52QR16pcu7vvnSnfra1e49RquRbm+Sf3xxtx5u3n3sosqEyhqfwta/AAwH5PrNSl2WgE7h1yYGQzrrG5W6DoX/q0qSJO2y8ZEkSa1h4yNJklqjEWt8srvF4Oy5eU9jtoawtNmv1Fo82e8zuHRpt87C7rMREHvuN1WsEte87JVDstut1MVJqvfuKewtjV6PpQuXDh6o/5tXfCRJUmvY+EiSpNaw8ZEkSa1h4yNJklqjEYub2yAGA5aurFdqqWlyMGRw48a8p6EJZX/A4PKV3TrL+7zJ4ZDh7duVuiTZ69N/5eLBAxdYbm3RP/ev3Tq3avm5XvGRJEmtYeMjSZJaw8ZHkiS1RmQDbuQVEevAGeAocHm0+Z2ZeWR+s5quMRmLygdmLIHnYhnMuPg8F2enKVd8zmTmCeByZp4YPT8z70lNWSUj5eUDM5bAc7EMZlx8nosz0pTGR5IkaeZsfCRJUms0pfF5at+f+5+XYH/G0vKBGUvguVgGMy4+z8UZacTiZkmSpDo05YqPJEnSzNn4SJKk1phL4xMRn4qIWxHRi4itiHgpIr66Z39ExLcjoh8RGRGbEXE7Ir4+j/neDzMufsbS84EZR/vN2HCl5wMzjvbXkzEza30AS8A14FvAP4B/A98D/gS8ZzTmY8CzwEXgOeC5uudpxnZnLD2fGc0473mbz4zzyjiPKz4PA6vAr4GzwHeAjwNPAydHY04CPxg9vw48EBFvqXmekzDjtkXOWHo+MKMZF0Pp+cCMtWacR+PzILAMHALOA38DjgAXRvt2xpwHEngUeAfw24h4b+2zvT9m3B2zqBlLzwdmNONiZCw9H5ix1ozL03yxvSLiV8Cbx+z66c6QMfty374PAS8DPwPeBvwcOD7FaU7EjNtDxuxbmIyl5wMz7gwZs8+MDcpYej4w486QMftqzTizxiczPzxue0R8APgSsMF2kHcD68AxtoPCdgd4PDN/N/o7b2L7ctgTEXE0My+/5oXnwIyLn7H0fGBGzAgLkLH0fGBGGpJxZo3PPfwB6AEfBB4C3g/8BHgc+MxozDPAlyPieeCNbP/jfAToA1fqnvB9MOO2Rc5Yej4woxkXI2Pp+cCMtWasfY1PZvaBz7Pd+R0HHgAeAf4JPBYRfxltfxX4O/B74H2jcZ/M0dLvJjPj4mcsPR+YETMuRMbS84EZqTmjX1khSZJawzs3S5Kk1rDxkSRJrWHjI0mSWsPGR5IktYaNjyRJag0bH0mS1Bo2PpIkqTX+C2mTdrAEqRaHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 10, figsize=(10, 10))\n",
    "for i, row in enumerate(train.sample(10).values):\n",
    "    filepath, label = row[1], row[2]\n",
    "    freq = process_wav(ROOT_DIR, filepath)\n",
    "    ax[i].imshow(freq.unsqueeze(1))\n",
    "    ax[i].set_title(f\"{label}\")\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreqDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = [[], []]\n",
    "        for filename, target in tqdm(zip(data[\"wav_path\"], data[\"target\"]), total=len(data)):\n",
    "            target_ = torch.tensor(target).long()\n",
    "            freq = process_wav(ROOT_DIR, filename).unsqueeze(0)\n",
    "            self.data[0].append(freq)\n",
    "            self.data[1].append(target_)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[0][index], self.data[1][index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.data[0]) == len(self.data[1])\n",
    "        return len(self.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bb5929d8f741f18f5ddd0643cf517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20475.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac8fca3c6bf410ab88b7350b9ad7189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6825.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FreqDataset(train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True)\n",
    "validation_dataset = FreqDataset(val)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=32, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([32, 1, 128])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "batch_X_train, batch_y_train = next(iter(train_dataloader))\n",
    "print(type(batch_X_train), batch_X_train.shape)\n",
    "print(type(batch_y_train), batch_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FreqNet(nn.Module):\n",
    "    # big model\n",
    "    def __init__(self, N):\n",
    "        super(FreqNet, self).__init__()\n",
    "        # head\n",
    "        self.conv = nn.Conv1d(1, 64, 4, stride=2)\n",
    "        self.batchnorm = nn.BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        # block 1\n",
    "        self.conv1_1 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.drop1_1 = nn.Dropout(0.2)\n",
    "        self.batchnorm1_1 = nn.BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_1 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        # block 2\n",
    "        self.conv1_2 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.drop1_2 = nn.Dropout(0.2)\n",
    "        self.batchnorm1_2 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu_2 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv3_2 = nn.Conv1d(64, 128, kernel_size=1, stride=2, padding=1, bias=False)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        # block 3\n",
    "#         self.conv1_3 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.drop1_3 = nn.Dropout(0.2)\n",
    "#         self.batchnorm1_3 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#         self.relu_3 = nn.ReLU(inplace=True)\n",
    "#         self.conv2_3 = nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.batchnorm2_3 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#         self.conv3_3 = nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=1, bias=False)\n",
    "#         self.batchnorm2_3 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "#         # block 3\n",
    "#         self.conv1_4 = nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.drop1_4 = nn.Dropout(0.2)\n",
    "#         self.batchnorm1_4 = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#         self.relu_4 = nn.ReLU(inplace=True)\n",
    "#         self.conv2_4 = nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.batchnorm2_4 = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#         self.conv3_4 = nn.Conv2d(256, 512, kernel_size=1, stride=2, padding=1, bias=False)\n",
    "#         self.batchnorm2_4 = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.finalpool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.linear = nn.Linear(128, N, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.to(device)\n",
    "        # head\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # block 1\n",
    "        x_remember = x.clone()\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.drop1_1(x)\n",
    "        x = self.batchnorm1_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.batchnorm2_1(x)\n",
    "        \n",
    "        x = x + x_remember\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # block 2\n",
    "        x_remember = x.clone()\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.drop1_2(x)\n",
    "        x = self.batchnorm1_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.batchnorm2_2(x)\n",
    "        x = x + F.pad(x_remember, [0, 0, 32, 32, 0, 0])\n",
    "        x = F.relu(x)\n",
    "\n",
    "#         # block 3\n",
    "#         x_remember = x.clone()\n",
    "#         x = self.conv1_3(x)\n",
    "#         x = self.drop1_3(x)\n",
    "#         x = self.batchnorm1_3(x)\n",
    "#         x = self.relu_3(x)\n",
    "#         x = self.conv2_3(x)\n",
    "#         x = self.batchnorm2_3(x)\n",
    "#         x = x + F.pad(x_remember, [0, 0, 64, 64, 0, 0])\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         # block 4\n",
    "#         x_remember = x.clone()\n",
    "#         x = self.conv1_4(x)\n",
    "#         x = self.drop1_4(x)\n",
    "#         x = self.batchnorm1_4(x)\n",
    "#         x = self.relu_4(x)\n",
    "#         x = self.conv2_4(x)\n",
    "#         x = self.batchnorm2_4(x)\n",
    "#         x = x + F.pad(x_remember, [0, 0, 128, 128, 0, 0])\n",
    "#         x = F.relu(x)\n",
    "\n",
    "        # end\n",
    "        x = self.finalpool(x)\n",
    "        #         print(x.shape)\n",
    "        x = self.linear(x.view(batch_size, -1))\n",
    "        #         x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FreqSimpleNet(nn.Module):\n",
    "    # small model\n",
    "    def __init__(self, N):\n",
    "        super(FreqSimpleNet, self).__init__()\n",
    "        # head\n",
    "        self.conv = nn.Conv1d(1, 64, 7, stride=2)\n",
    "        self.batchnorm = nn.BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=5, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "#         self.finalpool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.linear = nn.Linear(64*59, 64*30)\n",
    "    \n",
    "        # block 1\n",
    "        self.conv1_1 = nn.Conv1d(64, 128, kernel_size=4, stride=1, padding=1, bias=False)\n",
    "        self.drop1_1 = nn.Dropout(0.2)\n",
    "        self.batchnorm1_1 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_1 = nn.Conv1d(128, 128, kernel_size=4, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.linear1 = nn.Linear(128*28, N, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.to(device)\n",
    "        # head\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # block 1\n",
    "#         print(x.shape)\n",
    "        x = self.linear(x.view(batch_size, -1)).view(batch_size, 64, -1)\n",
    "        \n",
    "        x = self.conv1_1(x)\n",
    "        x = self.drop1_1(x)\n",
    "        x = self.batchnorm1_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.batchnorm2_1(x)\n",
    "#         print(x.shape)\n",
    "        x = self.linear1(x.view(batch_size, -1))\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqSimpleNet(\n",
       "  (conv): Conv1d(1, 64, kernel_size=(7,), stride=(2,))\n",
       "  (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=5, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  (linear): Linear(in_features=3776, out_features=1920, bias=True)\n",
       "  (conv1_1): Conv1d(64, 128, kernel_size=(4,), stride=(1,), padding=(1,), bias=False)\n",
       "  (drop1_1): Dropout(p=0.2, inplace=False)\n",
       "  (batchnorm1_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_1): ReLU(inplace=True)\n",
       "  (conv2_1): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(1,), bias=False)\n",
       "  (batchnorm2_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear1): Linear(in_features=3584, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FreqSimpleNet(3)\n",
    "# net = torchvision.models.resnet34(pretrained=True)\n",
    "# net.fc = nn.Linear(512, 50)\n",
    "# net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "net = net.to(device)\n",
    "history = []\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000005)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "net(batch_X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, train_dataloader, optimizer, loss):\n",
    "    net.train()\n",
    "    loss_train = []\n",
    "    \n",
    "    for batch_X, batch_y_true in train_dataloader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y_true = batch_y_true.to(device)\n",
    "        out = net(batch_X)\n",
    "        train_batch_loss = loss(out, batch_y_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_train.append(train_batch_loss.item())\n",
    "\n",
    "    return np.array(loss_train).mean()\n",
    "\n",
    "\n",
    "def validate(net, validation_dataloader, loss):\n",
    "    net.eval()\n",
    "    pred = torch.tensor([]).to(device)\n",
    "    true = torch.tensor([]).to(device)\n",
    "    loss_val = []\n",
    "    \n",
    "    for batch_X, batch_y_true in validation_dataloader:\n",
    "        batch_size = batch_X.size(0)\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y_true = batch_y_true.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = net(batch_X)\n",
    "            batch_y_pred = out.argmax(axis=1)\n",
    "        pred = torch.cat((pred, batch_y_pred))\n",
    "        true = torch.cat((true, batch_y_true))\n",
    "        \n",
    "        batch_loss = loss(out, batch_y_true)\n",
    "        loss_val.append(batch_loss.item())\n",
    "\n",
    "    acc = accuracy_score(true.cpu(), pred.cpu())\n",
    "    \n",
    "    return acc, np.array(loss_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ce4a8f4c0f499490fff1c2bd4caa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'train loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '45e2â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ef572e8d4c4b56a5d4a543dd951536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 500\n",
    "n_val = 2\n",
    "\n",
    "losses_train = []\n",
    "epochs_train = []\n",
    "losses_val = []\n",
    "accs_val = []\n",
    "epochs_val = []\n",
    "\n",
    "fig_loss = make_subplots(\n",
    "    cols=2, rows=1,\n",
    "    subplot_titles=['Loss', 'Accuracy'], column_widths=[0.7, 0.3]\n",
    "    \n",
    ")\n",
    "\n",
    "fig_loss.add_scatter(\n",
    "    y=losses_train, x=epochs_train,\n",
    "    name='train loss', row=1, col=1\n",
    ")\n",
    "fig_loss.add_scatter(\n",
    "    y=losses_val, x=epochs_val,\n",
    "    name='validation loss', row=1, col=1\n",
    ")\n",
    "fig_loss.add_scatter(\n",
    "    y=losses_val, x=epochs_val,\n",
    "    name='validation accuracy', row=1, col=2\n",
    ")\n",
    "fig_loss.update_layout(height=500, width=1300, title_text='FreqNet1d')\n",
    "fig_loss = go.FigureWidget(fig_loss)\n",
    "display(fig_loss)\n",
    "\n",
    "if not os.path.exists(\"models\\\\tmp\\\\1d\"):\n",
    "        os.makedirs(\"models\\\\tmp\\\\1d\")\n",
    "        \n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "#     loss_train = train_epoch(net, train_dataloader, optimizer, loss)\n",
    "    loss_train = train_epoch(net, train_dataloader, optimizer, loss)\n",
    "    losses_train.append(loss_train)\n",
    "    epochs_train.append(epoch)\n",
    "    \n",
    "    if epoch % n_val == 0:\n",
    "        acc, loss_val = validate(net, validation_dataloader, loss)\n",
    "        accs_val.append(acc)\n",
    "        losses_val.append(loss_val)\n",
    "        epochs_val.append(epoch)\n",
    "        \n",
    "    fig_loss.data[0].x = epochs_train\n",
    "    fig_loss.data[0].y = losses_train\n",
    "    \n",
    "    fig_loss.data[1].x = epochs_val\n",
    "    fig_loss.data[1].y = losses_val\n",
    "    \n",
    "    fig_loss.data[2].x = epochs_val\n",
    "    fig_loss.data[2].y = accs_val\n",
    "    \n",
    "    torch.save(net.state_dict(), f\"models\\\\tmp\\\\1d\\\\{epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose the best model according to the maximu of validation accuracy. The model on different training epochs is saved at tmp\\\\1d.\n",
    "\n",
    "Cross validation is recommended to prevent overfitting to the validation set, but I don't have the resources to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_epoch = torch.tensor(accs_val).argmax().item()*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqSimpleNet(\n",
       "  (conv): Conv1d(1, 64, kernel_size=(7,), stride=(2,))\n",
       "  (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=5, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  (linear): Linear(in_features=3776, out_features=1920, bias=True)\n",
       "  (conv1_1): Conv1d(64, 128, kernel_size=(4,), stride=(1,), padding=(1,), bias=False)\n",
       "  (drop1_1): Dropout(p=0.2, inplace=False)\n",
       "  (batchnorm1_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_1): ReLU(inplace=True)\n",
       "  (conv2_1): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(1,), bias=False)\n",
       "  (batchnorm2_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear1): Linear(in_features=3584, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FreqSimpleNet(3)\n",
    "net.load_state_dict(torch.load(f\"models\\\\tmp\\\\1d\\\\{best_acc_epoch}\"))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val/e/b7cf2c4.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val/0/8f1489d.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val/f/14b7304.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val/2/3763132.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val/0/51c4271.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wav_path  target\n",
       "0  val/e/b7cf2c4.wav       0\n",
       "1  val/0/8f1489d.wav       0\n",
       "2  val/f/14b7304.wav       0\n",
       "3  val/2/3763132.wav       0\n",
       "4  val/0/51c4271.wav       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_features = pd.read_csv('sample_submission.csv')\n",
    "submit_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = []\n",
    "        for filename in tqdm(data[\"wav_path\"], total=len(data)):\n",
    "            self.data.append(filename)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return process_wav(ROOT_DIR, self.data[index]).unsqueeze(0), self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e61ef890cd48fd897b4550aeda57b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=55200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submission_dataset = SubmissionDataset(submit_features)\n",
    "submission_dataloader = torch.utils.data.DataLoader(submission_dataset, batch_size=32, drop_last=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    }
   ],
   "source": [
    "if input() == 'y':\n",
    "    submission = pd.DataFrame(columns=['wav_path', 'target'])\n",
    "    submission.to_csv('submission-1d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391742f345aa41f0b1eb2df24e82454e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1725.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "for batch_X, batch_wav_path in tqdm(submission_dataloader):\n",
    "    batch_X = batch_X.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = net(batch_X)\n",
    "        \n",
    "        batch_y_pred = out.argmax(axis=1).cpu().numpy().astype(int)\n",
    "        batch_submission = pd.DataFrame({'wav_path': batch_wav_path, 'target': batch_y_pred})\n",
    "        batch_submission.to_csv('submission-1d.csv', mode='a', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
